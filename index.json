[{"content":"1.镜像仓库的原理与搭建 2.镜像安全 3.基于kubernetes的DevOps 计划、开发、测试、生产运维 git版本管理，镜像版本管理 通过代码变更触发生产部署更新，gitOps 4.基于Github Action、Jenkins的自动化流水线 docker in docker方案\n挂载docker.sock到容器内 使用谷歌的kaniko方案 5.基于声明式API的自动化流水线：Tekton 6.连续交付工具：Argo CD 7.日志收集与分析 日志收集工具Grafana loki 8.构建监控系统 课后练习 本周没有好好实操部署prometheus，只完成过了http server的改造，代码参考孟老师视频内的内容。完整代码链接\n为 HTTPServer 添加 0-2 秒的随机延时； func DelayedHello(w http.ResponseWriter, r *http.Request) { glog.V(4).Info(\u0026#34;entering root handler\u0026#34;) timer := metrics.NewTimer() defer timer.ObserveTotal() user := r.URL.Query().Get(\u0026#34;user\u0026#34;) delay := randRange(0, 2000) // 0～2s的时延 time.Sleep(time.Duration(delay) * time.Millisecond) if user != \u0026#34;\u0026#34; { io.WriteString(w, fmt.Sprintf(\u0026#34;hello [%s]\\n\u0026#34;, user)) } else { io.WriteString(w, \u0026#34;hello [stranger]\\n\u0026#34;) } io.WriteString(w, \u0026#34;===================Details of the http request header:============\\n\u0026#34;) for k, v := range r.Header { io.WriteString(w, fmt.Sprintf(\u0026#34;%s=%s\\n\u0026#34;, k, v)) } glog.V(4).Infof(\u0026#34;Respond in %d ms\u0026#34;, delay) } func randRange(min int, max int) int { rand.Seed(time.Now().UnixNano()) return rand.Intn(max-min+1) + min } 为 HTTPServer 项目添加延时 Metric； func newServerHandler() *http.ServeMux { interceptor := func(hf http.HandlerFunc) http.HandlerFunc { return middleware.SetVersion(middleware.GetIP(middleware.GetResponseStatus(hf))) } mux := http.NewServeMux() mux.HandleFunc(\u0026#34;/\u0026#34;, interceptor(handler.Index)) mux.HandleFunc(\u0026#34;/healthz\u0026#34;, interceptor(handler.Healthz)) mux.HandleFunc(\u0026#34;/hello\u0026#34;, handler.DelayedHello) // 添加时延metric mux.Handle(\u0026#34;/metrics\u0026#34;, promhttp.Handler()) return mux } 将 HTTPServer 部署至测试集群，并完成 Prometheus 配置； 此部分主要修改deployment文件，在pod的定义里添加prometheus相关注解，完整文件链接\nmetadata: annotation: prometheus.io/scrape: \u0026#34;true\u0026#34; prometheus.io/port: \u0026#34;8080\u0026#34; 从 Prometheus 界面中查询延时指标数据；（暂未完成） （可选）创建一个 Grafana Dashboard 展现延时分配情况。（暂未完成） ","permalink":"https://giuliao.github.io/blog/posts/geektime-cn/10-kubernetes%E7%9A%84%E7%94%9F%E4%BA%A7%E5%8C%96%E8%BF%90%E7%BB%B4/","summary":"1.镜像仓库的原理与搭建 2.镜像安全 3.基于kubernetes的DevOps 计划、开发、测试、生产运维 git版本管理，镜像版本管理 通过代码变更触发生产部署更新，gitOps 4.基于Github Action、Jenkins的自动化流水线 docker in docker方案\n挂载docker.sock到容器内 使用谷歌的kaniko方案 5.基于声明式API的自动化流水线：Tekton 6.连续交付工具：Argo CD 7.日志收集与分析 日志收集工具Grafana loki 8.构建监控系统 课后练习 本周没有好好实操部署prometheus，只完成过了http server的改造，代码参考孟老师视频内的内容。完整代码链接\n为 HTTPServer 添加 0-2 秒的随机延时； func DelayedHello(w http.ResponseWriter, r *http.Request) { glog.V(4).Info(\u0026#34;entering root handler\u0026#34;) timer := metrics.NewTimer() defer timer.ObserveTotal() user := r.URL.Query().Get(\u0026#34;user\u0026#34;) delay := randRange(0, 2000) // 0～2s的时延 time.Sleep(time.Duration(delay) * time.Millisecond) if user != \u0026#34;\u0026#34; { io.WriteString(w, fmt.Sprintf(\u0026#34;hello [%s]\\n\u0026#34;, user)) } else { io.WriteString(w, \u0026#34;hello [stranger]\\n\u0026#34;) } io.","title":"模块十：kubernetes的生产化运维"},{"content":"1.深入理解pod的生命周期 2.服务发现 3.Service对象 Service类型:\nClusterIP NodePort LoadBalancer Headless ExternalName Service的拓扑支持\n4.kube-proxy组件 iptables相关命令\niptables -L -d nat #查看nat类型的iptables规则 iptables-save -t nat # 查看在本机执行过的iptable命令 iptable切换ipvs的操作\n企业外部访问k8s内部服务方案：\n创建dns记录指向内部loadbalancer的vip 5.DNS原理和实践 6.Ingress对象 7.案例分享 课后作业 第一部分 作业要求：编写 Kubernetes 部署脚本将 httpserver 部署到 Kubernetes 集群，以下是你可以思考的维度。\n完整yaml脚本点击链接 完整http server代码点击链接\n1. 优雅启动\n主要体现在存活探针，可参见4探活部分\n2. 优雅终止\n主要分为两部分，容器脚本处理，httpserver代码逻辑处理。\n在部署的deployment里面设置preStop lifecycle. 主要为shell脚本循环调用killall 确保进程已被kill。killall比起kill的优势在于，应用被kill返回0未被kill返回1.\nlifecycle: preStop: exec: command: [ \u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;while killall /bin/server; do sleep 1; done\u0026#34; ] 应用的优雅关闭代码如下，具体解释请参考注释：\nfunc gracefullyExit(server *http.Server) { ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() glog.Info(\u0026#34;server will shutdown in 5 seconds\u0026#34;) // https://stackoverflow.com/questions/39320025/how-to-stop-http-listenandserve if err := server.Shutdown(ctx); err != nil { glog.Fatal(err) } } // https://cloud.tencent.com/developer/article/1645996 func dealSysSignal(server *http.Server, wg *sync.WaitGroup, c chan os.Signal) { // 一旦接受到中断信号就跳出循环，防止脚本循环发kill消息，反复执行gracefullExit函数调用 Loop: for s := range c { switch s { case syscall.SIGHUP, syscall.SIGINT, syscall.SIGTERM, syscall.SIGQUIT: break Loop } } // 优雅关闭主逻辑 gracefullyExit(server) wg.Done() } func newServerHandler() *http.ServeMux { interceptor := func(hf http.HandlerFunc) http.HandlerFunc { return middleware.SetVersion(middleware.GetIP(middleware.GetResponseStatus(hf))) } mux := http.NewServeMux() mux.HandleFunc(\u0026#34;/\u0026#34;, interceptor(handler.Index)) mux.HandleFunc(\u0026#34;/healthz\u0026#34;, interceptor(handler.Healthz)) return mux } func main() { flag.Parse() wg := \u0026amp;sync.WaitGroup{} server := http.Server{Addr: fmt.Sprintf(\u0026#34;:%d\u0026#34;, portFlag), Handler: newServerHandler()} // 1. 设置关闭server的回调函数，通过waitgroup确保调用完成 wg.Add(1) server.RegisterOnShutdown(func() { wg.Done() glog.Info(\u0026#34;server is shutdown\u0026#34;) }) // 2. 设置中断信号监听 c := make(chan os.Signal) signal.Notify(c, syscall.SIGHUP, syscall.SIGINT, syscall.SIGTERM) wg.Add(1) // 3. 处理中断信号goroutine go dealSysSignal(\u0026amp;server, wg, c) err := server.ListenAndServe() if err != nil \u0026amp;\u0026amp; err != http.ErrServerClosed { glog.Fatal(err) } // 4. 等待函数处理完成功返回 wg.Wait() // 5. 关闭中断信号监听，关闭channel // avoid send close channel signal.Stop(c) close(c) os.Exit(0) } 测试说明：deployment设置rs为0，再观察pod日志\nkubectl edit deploy -n wg-ns simple-server # 设置rs为0 kubectl logs -f -n wg-ns simple-server-8476997874-n88gv # 监听日志 查看pod的logs具体日志信息如下：\nI1120 07:37:53.908754 1 interceptor.go:65] request /healthz status code 200 I1120 07:37:53.908761 1 interceptor.go:78] request /healthz ip addr 172.21.0.114 I1120 07:38:00.056977 1 main.go:33] server will shutdown in 5 seconds I1120 07:38:00.057048 1 main.go:72] server is shutdown 3. 资源需求和 QoS 保证\n这部分应该给应用做一个压测，评估初步的内存和cpu使用。当前使用浏览器不停服务路径，并根据top命令做了个初步的测试\ntop -pid \u0026lt;processid\u0026gt; 连续不停访问cpu会轻微上涨，停止访问后就下降。内存短时间内飙升，过个几分钟下降到3M左右\n%CPU MEM 0.1% 2944K resources: limits: cpu: 1000m memory: 1024Mi requests: cpu: 700m memory: 200Mi 4. 探活\n探活yaml信息如下：\nlivenessProbe: failureThreshold: 5 httpGet: path: /healthz port: 8080 scheme: HTTP initialDelaySeconds: 60 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 5 readinessProbe: failureThreshold: 3 httpGet: path: /healthz port: 8080 scheme: HTTP periodSeconds: 10 successThreshold: 1 timeoutSeconds: 1 5. 日常运维需求，日志等级\n日志等级体现在应用启动参数,这部分在dockerfile内就固定了，但是可通过启动命令覆盖CMD内的启动参数。\nENTRYPOINT [\u0026#34;/bin/server\u0026#34;] CMD [\u0026#34;-logtostderr=true\u0026#34;, \u0026#34;-port=8080\u0026#34;] 6. 配置和代码分离\n配置主要体现在访问server时会在response添加version信息，该部分使用configmap生成配置注入到pod中\napiVersion: v1 kind: ConfigMap metadata: name: simple-server-env-config namespace: wg-ns data: version: v2 第二部分 来尝试用 Service, Ingress 将你的服务发布给集群外部的调用方吧。 在第一部分的基础上提供更加完备的部署 spec，包括（不限于）：\n1. Service\n服务的yaml如下：\napiVersion: v1 kind: Service metadata: name: simple-server-yml namespace: wg-ns spec: type: ClusterIP ports: - port: 80 targetPort: 8080 protocol: TCP name: http selector: app: simple-server 应用高可用主要有两点：\npod多实例部署，通过service实现负载均衡 pod之间相互反亲和，同时部署在不同的节点上 在添加反亲和之前可以看到有两个pod部署在同一个node1上 wggg@node1:~$ kubectl get pod -n wg-ns simple-server-8476997874-jfrtm -o yaml | grep nodeName nodeName: node1 wggg@node1:~$ kubectl get pod -n wg-ns simple-server-8476997874-vpr85 -o yaml | grep nodeName nodeName: node1 wggg@node1:~$ kubectl get pod -n wg-ns simple-server-8476997874-wj94j -o yaml | grep nodeName nodeName: node2 添加pod反亲和性：\naffinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: - simple-server topologyKey: kubernetes.io/hostname 重新获取pod的信息如下：\nwggg@node1:~$ kubectl get pod -n wg-ns simple-server-644cfdb7d8-4d59d -o yaml | grep nodeName nodeName: master wggg@node1:~$ kubectl get pod -n wg-ns simple-server-8476997874-vpr85 -o yaml | grep nodeName nodeName: node1 wggg@node1:~$ kubectl get pod -n wg-ns simple-server-8476997874-wj94j -o yaml | grep nodeName nodeName: node2 另外一个被驱逐的pod需要手动删除\n2. Ingress\ningress的yaml如下\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: gateway annotations: kubernetes.io/ingress.class: \u0026#34;nginx\u0026#34; spec: # tls: # - hosts: # - wggg.com rules: - host: wggg.com http: paths: - path: \u0026#34;/\u0026#34; pathType: Prefix backend: service: name: simple-server-yml port: number: 80 如何通过证书保证 httpServer 的通讯安全。\ningress实现https 应用自身实现https通信 其他事宜 现象一：修复coreDNS的ready probe问题，以及master节点not ready的问题\n通过查看kubelet的日志发现是主机改名了导致的链接失败问题\n问题排查过程中尝试了以下一些方法：\n方式一：直接kubectl edit节点的名称信息，但是metadata的内容是无法修改的 方式二：导出原有的节点yaml替换节点名称后再新建，使用kubeadm重建kubeconfig文件最后重启kubelet解决，参考如下的2 参考：\n1.新建pod调试技巧 2.节点重置名字后，使用kubeadm进行修复 现象二：namespace里面存在deployment资源但是在未删除的情况直接删除namespace\nnamespace 一直处理terminating状态\n解决手段：\n清空namespace里的finalizer 查询未删除的资源并进行删除（但是deployment资源是看不到的，k8s也的确做了删除操作） 参考：\nnamespace-stuck-as-terminating-how-i-removed-it ","permalink":"https://giuliao.github.io/blog/posts/geektime-cn/8-%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E7%AE%A1%E7%90%86%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/","summary":"1.深入理解pod的生命周期 2.服务发现 3.Service对象 Service类型:\nClusterIP NodePort LoadBalancer Headless ExternalName Service的拓扑支持\n4.kube-proxy组件 iptables相关命令\niptables -L -d nat #查看nat类型的iptables规则 iptables-save -t nat # 查看在本机执行过的iptable命令 iptable切换ipvs的操作\n企业外部访问k8s内部服务方案：\n创建dns记录指向内部loadbalancer的vip 5.DNS原理和实践 6.Ingress对象 7.案例分享 课后作业 第一部分 作业要求：编写 Kubernetes 部署脚本将 httpserver 部署到 Kubernetes 集群，以下是你可以思考的维度。\n完整yaml脚本点击链接 完整http server代码点击链接\n1. 优雅启动\n主要体现在存活探针，可参见4探活部分\n2. 优雅终止\n主要分为两部分，容器脚本处理，httpserver代码逻辑处理。\n在部署的deployment里面设置preStop lifecycle. 主要为shell脚本循环调用killall 确保进程已被kill。killall比起kill的优势在于，应用被kill返回0未被kill返回1.\nlifecycle: preStop: exec: command: [ \u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;while killall /bin/server; do sleep 1; done\u0026#34; ] 应用的优雅关闭代码如下，具体解释请参考注释：\nfunc gracefullyExit(server *http.Server) { ctx, cancel := context.","title":"模块八：生命周期管理和服务发现"},{"content":"1.从系统架构谈起 微服务改造 除了遵循分离微服务的方法建议，也要从公司的人力成本，维护团队管辖的功能范围进行考虑拆分\n微服务间通讯 点对点通讯 使用api网关统一管理访问（包含身份认证、鉴权能力） 2.理解Docker 3.Docker核心技术 4.容器网络 5.Dockerfile的最佳实践 多段构建\ndocker常用指令\nfrom as \u0026hellip; run add：从源地址复制到目的地址，add会做解压缩操作 copy：从源地址 课后练习 3.1 Memory 子系统练习\n在 cgroup memory 子系统目录中创建目录结构\ncd /sys/fs/cgroup/memory mkdir memorydemo cd memorydemo 运行 malloc（在 linux 机器 make build）\n查看内存使用情况\nwatch \u0026#39;ps -aux|grep malloc|grep -v grep‘ 通过 cgroup 限制 memory\n把进程添加到 cgroup 进程配置组 echo ps -ef|grep malloc |grep -v grep|awk ‘{print $2}’ \u0026gt; cgroup.procs 设置 memory.limit_in_bytes echo 104960000 \u0026gt; memory.limit_in_bytes 等待进程被 oom kill\n思考题：容器的劣势 加了容器层对性能的影响 容器内的问题排查，集成测试时日志、监控系统的建设 课后练习 3.2 1. 构建本地镜像 docker build -f ./module3-Dockerfile 报错记录1: 无法拷贝上级目录的文\nStep 3/9 : COPY ../module2/ /go/src COPY failed: forbidden path outside the build context: ../module2/ () 解决方案：移动dockerfile到父级目录，然后重新执行build\n报错记录2: mac os下无法正常build\nfailed to solve with frontend dockerfile.v0: failed to read dockerfile: open /var/lib/docker/tmp/buildkit-mount3040494485/module3-Dockerfile: no such file or directory 解决方案：\nexport DOCKER_BUILDKIT=0 export COMPOSE_DOCKER_CLI_BUILD=0 2.编写 Dockerfile 将练习 2.2 编写的 httpserver 容器化 Dockerfile如下\n# stage1: build binary FROM golang:1.19.2-alpine3.16 AS build RUN apk add --no-cache git COPY ./module2/ /go/src/module2 WORKDIR /go/src/module2 RUN go build -o /bin/server # stage2: build imag # FROM scratch # error exec ./server: no such file or directory FROM alpine:latest WORKDIR / COPY --from=build /bin/server /bin/server ENV VERSION v1 CMD [\u0026#34;/bin/server\u0026#34;] 执行如下命令构建\ndocker build -f module3-Dockerfile . --target build -t module3-build-stage docker build -f module3-Dockerfile . -t giuliao/module3-httpserver:v1.0 docker rmi module3-build-stage 报错记录：用scratch做为基础镜像编译出来的镜像会报如下错误，暂时没有找到解决方案 exec /bin/server: no such file or directory 3.将镜像推送至 docker 官方镜像仓库 docker push giuliao/module3-httpserver:v1.0 dockerhub访问链接 4.通过 docker 命令本地启动 httpserver 启动命令\ndocker run -it -p 3000:3000 giuliao/module3-httpserver:v1.0 日志记录\nI1016 03:07:24.903419 1 main.go:129] response status code 200, ip addr 172.17.0.1 I1016 03:07:25.221227 1 main.go:129] response status code 200, ip addr 172.17.0.1 2022/10/16 03:07:34 http: superfluous response.WriteHeader call from main.(*loggingResponseWriter).WriteHeader (main.go:81) I1016 03:07:34.660287 1 main.go:129] response status code 200, ip addr 172.17.0.1 I1016 03:07:34.928845 1 main.go:129] response status code 200, ip addr 172.17.0. 5.通过 nsenter 进入容器查看 IP 配置 查看容器在宿主机的pid\ndocker inspect -f \u0026#39;{{.State.Pid}}\u0026#39; \u0026lt;containerID\u0026gt; 参考链接 nsenter -t \u0026lt;pid\u0026gt; -n ip addr ","permalink":"https://giuliao.github.io/blog/posts/geektime-cn/3-docker-tech/","summary":"1.从系统架构谈起 微服务改造 除了遵循分离微服务的方法建议，也要从公司的人力成本，维护团队管辖的功能范围进行考虑拆分\n微服务间通讯 点对点通讯 使用api网关统一管理访问（包含身份认证、鉴权能力） 2.理解Docker 3.Docker核心技术 4.容器网络 5.Dockerfile的最佳实践 多段构建\ndocker常用指令\nfrom as \u0026hellip; run add：从源地址复制到目的地址，add会做解压缩操作 copy：从源地址 课后练习 3.1 Memory 子系统练习\n在 cgroup memory 子系统目录中创建目录结构\ncd /sys/fs/cgroup/memory mkdir memorydemo cd memorydemo 运行 malloc（在 linux 机器 make build）\n查看内存使用情况\nwatch \u0026#39;ps -aux|grep malloc|grep -v grep‘ 通过 cgroup 限制 memory\n把进程添加到 cgroup 进程配置组 echo ps -ef|grep malloc |grep -v grep|awk ‘{print $2}’ \u0026gt; cgroup.procs 设置 memory.limit_in_bytes echo 104960000 \u0026gt; memory.limit_in_bytes 等待进程被 oom kill","title":"模块三：Docker核心技术"},{"content":"笔记 1. 线程加锁 sync.Mutex：Lock()加锁，Unlock()解锁 sync.RWMutex：不限制读，只限制并发写和并发读写 sync.WaitGroup：等待一组 goroutine 返回 sync.Once：保证某段代码只执行一次 sync.Cond：让一组 goroutine 在满足特定条件时被唤醒 2. 线程调度 进程和线程间共享 Memory Manage、fs、files、signal 调用线程不需要切换上下文，但仍然涉及系统调用 用户态线程解决了系统调用问题，Go 语言基于 GMP 实现用户态线程 3. Go 语言内存管理 4. 包引用与依赖管理，Makefile 项目编译 go mod replace 用法，使用原始 import 路径，替换源为私有地址\nmakefile\nroot: export ROOT=github.com/cncamp/golang; .PHONY: root release: echo \u0026#34;building httpserver binary\u0026#34; mkdir -p bin/amd64 CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o bin/amd64 . .PHONY: release 5. 动手编写一个 HTTP Server Go httpserver 底层实现（参考） 6. Go 语言调试 go 专属调试工具 dlv\nglog 日志工具\n性能分析工具\npprof 中 top 各个字段的含义（参考）： flat：函数在 CPU 上运行的时间 flat%：函数在CPU上运行时间的百分比 sum%：是从上到当前行所有函数累加使用 CPU 的比例 cum：这个函数以及子函数运行所占用的时间，应该大于等于flat cum%：这个函数以及子函数运行所占用的比例，应该大于等于flat% linux top 指标中的含义（参考）\n7. kubernetes 中如何使用 Go 语言 课后练习 2.1 将练习 1.2 中的生产者消费者模型修改为多个生产者和多个消费者模式 que := make(chan int, 10) ticker := time.NewTicker(time.Second) ctx, cancel := context.WithCancel(context.Background()) wg := sync.WaitGroup{} producerNum := 10 customerNum := 10 wg.Add(producerNum + customerNum) // producer for i := 0; i \u0026lt; producerNum; i++ { go func(n int) { for { select { case \u0026lt;-ticker.C: que \u0026lt;- n case \u0026lt;-ctx.Done(): wg.Done() fmt.Printf(\u0026#34;producer %d exit\\n\u0026#34;, n) return } } }(i) } // consumer for i := 0; i \u0026lt; customerNum; i++ { go func(n int) { for { select { case v := \u0026lt;-que: fmt.Printf(\u0026#34;consume data %d\\n\u0026#34;, v) case \u0026lt;-ctx.Done(): wg.Done() fmt.Printf(\u0026#34;consumer %d exit\\n\u0026#34;, n) return } } }(i) } time.Sleep(20 * time.Second) cancel() wg.Wait() 课后练习 2.2 接收客户端 request，并将 request 中带的 header 写入 response header 读取当前系统的环境变量中的 VERSION 配置，并写入 response header Server 端记录访问日志包括客户端 IP，HTTP 返回码，输出到 server 端的标准输出 当访问 localhost/healthz 时，应返回 200 // 参考：https://gist.github.com/Boerworz/b683e46ae0761056a636 type loggingResponseWriter struct { http.ResponseWriter statusCode int } func NewLoggingResponseWriter(w http.ResponseWriter) *loggingResponseWriter { // WriteHeader(int) is not called if our response implicitly returns 200 OK, so // we default to that status code. return \u0026amp;loggingResponseWriter{w, http.StatusOK} } func (lrw *loggingResponseWriter) WriteHeader(code int) { lrw.statusCode = code lrw.ResponseWriter.WriteHeader(code) } // getIP returns the ip address from the http request // 参考：https://gist.github.com/miguelmota/7b765edff00dc676215d6174f3f30216 func getIP(r *http.Request) (string, error) { ips := r.Header.Get(\u0026#34;X-Forwarded-For\u0026#34;) splitIps := strings.Split(ips, \u0026#34;,\u0026#34;) if len(splitIps) \u0026gt; 0 { // get last IP in list since ELB prepends other user defined IPs, meaning the last one is the actual client IP. netIP := net.ParseIP(splitIps[len(splitIps)-1]) if netIP != nil { return netIP.String(), nil } } ip, _, err := net.SplitHostPort(r.RemoteAddr) if err != nil { return \u0026#34;\u0026#34;, err } netIP := net.ParseIP(ip) if netIP != nil { ip := netIP.String() if ip == \u0026#34;::1\u0026#34; { return \u0026#34;127.0.0.1\u0026#34;, nil } return ip, nil } return \u0026#34;\u0026#34;, errors.New(\u0026#34;IP not found\u0026#34;) } // 每个请求都要记录日志需要使用拦截器 func interceptor(handler http.HandlerFunc) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { // 2. 读取当前系统的环境变量中的 VERSION 配置，并写入 response header w.Header().Add(\u0026#34;version\u0026#34;, os.Getenv(\u0026#34;VERSION\u0026#34;)) lrw := NewLoggingResponseWriter(w) handler(lrw, r) // 3.Server 端记录访问日志包括客户端 IP，HTTP 返回码，输出到 server 端的标准输出 addr, err := getIP(r) if err != nil { glog.Errorf(\u0026#34;get addr error %v\\n\u0026#34;, err) } glog.Infof(\u0026#34;response status code %d, ip addr %s\\n\u0026#34;, lrw.statusCode, addr) } } func main() { flag.Parse() http.HandleFunc(\u0026#34;/\u0026#34;, interceptor(func(w http.ResponseWriter, r *http.Request) { for k, v := range r.Header { // 1. 接收客户端 request，并将 request 中带的 header 写入 response header w.Header().Add(k, strings.Join(v, \u0026#34;, \u0026#34;)) } })) http.HandleFunc(\u0026#34;/healthz\u0026#34;, interceptor(func(w http.ResponseWriter, r *http.Request) { // 4. 当访问 localhost/healthz 时，应返回 200 w.WriteHeader(http.StatusOK) })) http.ListenAndServe(\u0026#34;:3000\u0026#34;, nil) } makefile\nrun: go run main.go -logtostderr true .PHONY: run 执行代码\nmake run ","permalink":"https://giuliao.github.io/blog/posts/geektime-cn/2-writing-go/","summary":"笔记 1. 线程加锁 sync.Mutex：Lock()加锁，Unlock()解锁 sync.RWMutex：不限制读，只限制并发写和并发读写 sync.WaitGroup：等待一组 goroutine 返回 sync.Once：保证某段代码只执行一次 sync.Cond：让一组 goroutine 在满足特定条件时被唤醒 2. 线程调度 进程和线程间共享 Memory Manage、fs、files、signal 调用线程不需要切换上下文，但仍然涉及系统调用 用户态线程解决了系统调用问题，Go 语言基于 GMP 实现用户态线程 3. Go 语言内存管理 4. 包引用与依赖管理，Makefile 项目编译 go mod replace 用法，使用原始 import 路径，替换源为私有地址\nmakefile\nroot: export ROOT=github.com/cncamp/golang; .PHONY: root release: echo \u0026#34;building httpserver binary\u0026#34; mkdir -p bin/amd64 CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o bin/amd64 . .PHONY: release 5. 动手编写一个 HTTP Server Go httpserver 底层实现（参考） 6. Go 语言调试 go 专属调试工具 dlv","title":"模块二：编写Go程序"},{"content":"作业 课后练习 1.1 编写一个小程序： 给定一个字符串数组 [“I”,“am”,“stupid”,“and”,“weak”] 用 for 循环遍历该数组并修改为 [“I”,“am”,“smart”,“and”,“strong”]\nfunc main() { initArr := []string{\u0026#34;I\u0026#34;, \u0026#34;am\u0026#34;, \u0026#34;stupid\u0026#34;, \u0026#34;and\u0026#34;, \u0026#34;weak\u0026#34;} for i, v := range initArr { if v == \u0026#34;stupid\u0026#34; { initArr[i] = \u0026#34;smart\u0026#34; } if v == \u0026#34;weak\u0026#34; { initArr[i] = \u0026#34;strong\u0026#34; } } fmt.Println(strings.Join(initArr, \u0026#34; \u0026#34;)) } 课后练习 1.2 基于 Channel 编写一个简单的单线程生产者消费者模型：\n队列：队列长度 10，队列元素类型为 int 生产者：每 1 秒往队列中放入一个类型为 int 的元素，队列满时生产者可以阻塞 消费者：每一秒从队列中获取一个元素并打印，队列为空时消费者阻塞 func main() { que := make(chan int, 10) ticker := time.NewTicker(time.Second) ctx, cancel := context.WithCancel(context.Background()) // producer go func() { for { select { case \u0026lt;-ticker.C: que \u0026lt;- 1 case \u0026lt;-ctx.Done(): fmt.Println(\u0026#34;producer exit\u0026#34;) return } } }() // consumer go func() { for { select { case v := \u0026lt;-que: fmt.Printf(\u0026#34;consume data %d\\n\u0026#34;, v) case \u0026lt;-ctx.Done(): fmt.Println(\u0026#34;consumer exit\u0026#34;) return } } }() time.Sleep(time.Second * 10) cancel() time.Sleep(time.Second * 2) } ","permalink":"https://giuliao.github.io/blog/posts/geektime-cn/1-golang-chara/","summary":"作业 课后练习 1.1 编写一个小程序： 给定一个字符串数组 [“I”,“am”,“stupid”,“and”,“weak”] 用 for 循环遍历该数组并修改为 [“I”,“am”,“smart”,“and”,“strong”]\nfunc main() { initArr := []string{\u0026#34;I\u0026#34;, \u0026#34;am\u0026#34;, \u0026#34;stupid\u0026#34;, \u0026#34;and\u0026#34;, \u0026#34;weak\u0026#34;} for i, v := range initArr { if v == \u0026#34;stupid\u0026#34; { initArr[i] = \u0026#34;smart\u0026#34; } if v == \u0026#34;weak\u0026#34; { initArr[i] = \u0026#34;strong\u0026#34; } } fmt.Println(strings.Join(initArr, \u0026#34; \u0026#34;)) } 课后练习 1.2 基于 Channel 编写一个简单的单线程生产者消费者模型：\n队列：队列长度 10，队列元素类型为 int 生产者：每 1 秒往队列中放入一个类型为 int 的元素，队列满时生产者可以阻塞 消费者：每一秒从队列中获取一个元素并打印，队列为空时消费者阻塞 func main() { que := make(chan int, 10) ticker := time.","title":"模块一：Go 语言特性"}]